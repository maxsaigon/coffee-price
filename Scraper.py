import requests
from bs4 import BeautifulSoup
import json
import time
import random
from datetime import datetime
from typing import Dict, Optional, List
import logging

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class InvestingCoffeeScraper:
    """
    Scraper cho d·ªØ li·ªáu gi√° c√† ph√™ t·ª´ Investing.com
    """
    
    def __init__(self):
        self.session = requests.Session()
        self.setup_headers()
        
        # URLs cho c√°c lo·∫°i c√† ph√™ tr√™n Investing.com
        self.urls = {
            'robusta': {
                'url': 'https://www.investing.com/commodities/london-coffee',
                'name': 'Coffee Robusta (London)',
                'unit': 'USD/MT'  # USD per Metric Ton
            },
            'arabica': {
                'url': 'https://www.investing.com/commodities/us-coffee-c',
                'name': 'Coffee C Arabica (New York)',
                'unit': 'USc/lb'  # US cents per pound
            }
        }
        
    def setup_headers(self):
        """
        Thi·∫øt l·∫≠p headers ƒë·ªÉ tr√°nh b·ªã block
        """
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }
        self.session.headers.update(self.headers)
    
    def get_page_content(self, url: str) -> Optional[str]:
        """
        L·∫•y n·ªôi dung HTML c·ªßa trang
        """
        try:
            # Random delay ƒë·ªÉ tr√°nh rate limiting
            time.sleep(random.uniform(2, 4))
            
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            return response.text
            
        except requests.RequestException as e:
            logger.error(f"L·ªói khi truy c·∫≠p {url}: {e}")
            return None
    
    def parse_coffee_price(self, html: str, coffee_type: str) -> Dict:
        """
        Parse gi√° c√† ph√™ t·ª´ HTML
        """
        soup = BeautifulSoup(html, 'html.parser')
        data = {}
        
        try:
            # T√¨m gi√° hi·ªán t·∫°i - Investing.com th∆∞·ªùng d√πng class n√†y
            price_element = soup.find('div', {'data-test': 'instrument-price-last'})
            if not price_element:
                # Backup selector
                price_element = soup.find('span', {'class': 'text-2xl'})
                if not price_element:
                    price_element = soup.find('div', {'class': 'instrument-price_last'})
            
            if price_element:
                price_text = price_element.text.strip().replace(',', '')
                data['current_price'] = float(price_text)
            
            # T√¨m thay ƒë·ªïi gi√°
            change_element = soup.find('div', {'data-test': 'instrument-price-change'})
            if not change_element:
                change_element = soup.find('span', {'class': lambda x: x and 'instrument-price_change' in x})
            
            if change_element:
                change_text = change_element.text.strip()
                # X·ª≠ l√Ω format: +1.50 ho·∫∑c -1.50
                data['change'] = float(change_text.replace(',', '').replace('+', ''))
            
            # T√¨m ph·∫ßn trƒÉm thay ƒë·ªïi
            percent_element = soup.find('div', {'data-test': 'instrument-price-change-percent'})
            if not percent_element:
                percent_element = soup.find('span', {'class': lambda x: x and 'instrument-price_change-percent' in x})
            
            if percent_element:
                percent_text = percent_element.text.strip()
                # X·ª≠ l√Ω format: (+1.50%) ho·∫∑c (-1.50%)
                percent_clean = percent_text.replace('(', '').replace(')', '').replace('%', '').replace('+', '')
                data['change_percent'] = float(percent_clean)
            
            # T√¨m th√¥ng tin phi√™n giao d·ªãch
            # Gi√° m·ªü c·ª≠a
            open_element = soup.find('dd', {'data-test': 'open'})
            if not open_element:
                open_element = soup.find('span', text='Open')
                if open_element:
                    open_element = open_element.find_next_sibling('span')
            
            if open_element:
                data['open'] = float(open_element.text.strip().replace(',', ''))
            
            # Gi√° cao nh·∫•t trong ng√†y
            high_element = soup.find('dd', {'data-test': 'high'})
            if not high_element:
                high_element = soup.find('span', text="Day's Range")
                if high_element:
                    range_text = high_element.find_next_sibling('span').text
                    if ' - ' in range_text:
                        low, high = range_text.split(' - ')
                        data['day_low'] = float(low.strip().replace(',', ''))
                        data['day_high'] = float(high.strip().replace(',', ''))
            
            if high_element and 'day_high' not in data:
                data['day_high'] = float(high_element.text.strip().replace(',', ''))
            
            # Gi√° th·∫•p nh·∫•t trong ng√†y
            low_element = soup.find('dd', {'data-test': 'low'})
            if low_element and 'day_low' not in data:
                data['day_low'] = float(low_element.text.strip().replace(',', ''))
            
            # Volume giao d·ªãch
            volume_element = soup.find('dd', {'data-test': 'volume'})
            if not volume_element:
                volume_element = soup.find('span', text='Volume')
                if volume_element:
                    volume_element = volume_element.find_next_sibling('span')
            
            if volume_element:
                volume_text = volume_element.text.strip()
                # X·ª≠ l√Ω format: 1.2K, 1.5M, etc.
                volume_clean = volume_text.replace(',', '')
                if 'K' in volume_clean:
                    data['volume'] = float(volume_clean.replace('K', '')) * 1000
                elif 'M' in volume_clean:
                    data['volume'] = float(volume_clean.replace('M', '')) * 1000000
                else:
                    data['volume'] = float(volume_clean) if volume_clean.replace('.', '').isdigit() else 0
            
            # Th·ªùi gian c·∫≠p nh·∫≠t
            time_element = soup.find('time', {'data-test': 'timestamp'})
            if not time_element:
                time_element = soup.find('span', {'class': lambda x: x and 'instrument-metadata_time' in x})
            
            if time_element:
                data['last_update'] = time_element.text.strip()
            
            # Th√™m metadata
            data['coffee_type'] = coffee_type
            data['unit'] = self.urls[coffee_type]['unit']
            data['name'] = self.urls[coffee_type]['name']
            data['source'] = 'Investing.com'
            data['scraped_at'] = datetime.now().isoformat()
            
            logger.info(f"‚úÖ ƒê√£ l·∫•y gi√° {coffee_type}: ${data.get('current_price', 'N/A')}")
            
        except Exception as e:
            logger.error(f"L·ªói khi parse d·ªØ li·ªáu {coffee_type}: {e}")
            
        return data
    
    def get_vietnamese_coffee_prices(self) -> Dict:
        """
        L·∫•y gi√° c√† ph√™ Vi·ªát Nam t·ª´ c√°c ngu·ªìn kh√°c
        C√≥ th·ªÉ scrape t·ª´ giacaphe.com ho·∫∑c cafef.vn
        """
        vn_prices = {}
        
        try:
            # V√≠ d·ª• scraping t·ª´ m·ªôt trang tin Vi·ªát Nam
            # ƒê√¢y l√† placeholder - c·∫ßn ƒëi·ªÅu ch·ªânh theo c·∫•u tr√∫c th·ª±c t·∫ø
            
            # Option 1: Scrape t·ª´ cafef.vn
            cafef_url = "https://cafef.vn/hang-hoa-nguyen-lieu.chn"
            
            # Option 2: API t·ª´ m·ªôt s·ªë ngu·ªìn Vi·ªát Nam (n·∫øu c√≥)
            
            # Gi√° m·∫´u - thay b·∫±ng scraping th·ª±c t·∫ø
            vn_prices = {
                'robusta_daklak': {
                    'price': 122500,  # VND/kg
                    'change': 500,
                    'location': 'ƒê·∫Øk L·∫Øk',
                    'unit': 'VND/kg'
                },
                'robusta_lamDong': {
                    'price': 121800,
                    'change': 300,
                    'location': 'L√¢m ƒê·ªìng',
                    'unit': 'VND/kg'
                },
                'arabica_vn': {
                    'price': 95000,
                    'change': -1000,
                    'location': 'L√¢m ƒê·ªìng',
                    'unit': 'VND/kg'
                }
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi l·∫•y gi√° VN: {e}")
            
        return vn_prices
    
    def scrape_all_prices(self) -> Dict:
        """
        Scrape t·∫•t c·∫£ gi√° c√† ph√™
        """
        all_prices = {
            'international': {},
            'vietnam': {},
            'metadata': {
                'scraped_at': datetime.now().isoformat(),
                'status': 'success'
            }
        }
        
        # Scrape gi√° qu·ªëc t·∫ø t·ª´ Investing.com
        for coffee_type, info in self.urls.items():
            logger.info(f"üîÑ ƒêang scrape {coffee_type}...")
            
            html = self.get_page_content(info['url'])
            if html:
                price_data = self.parse_coffee_price(html, coffee_type)
                if price_data:
                    all_prices['international'][coffee_type] = price_data
            else:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu {coffee_type}")
        
        # L·∫•y gi√° Vi·ªát Nam
        vn_prices = self.get_vietnamese_coffee_prices()
        if vn_prices:
            all_prices['vietnam'] = vn_prices
        
        return all_prices
    
    def format_telegram_message(self, prices: Dict) -> str:
        """
        Format d·ªØ li·ªáu th√†nh tin nh·∫Øn Telegram
        """
        now = datetime.now().strftime("%d/%m/%Y %H:%M")
        message = f"‚òï **B√ÅO C√ÅO GI√Å C√Ä PH√ä**\n"
        message += f"üìÖ {now}\n"
        message += "=" * 35 + "\n\n"
        
        # Gi√° qu·ªëc t·∫ø
        if prices.get('international'):
            message += "üåç **TH·ªä TR∆Ø·ªúNG QU·ªêC T·∫æ**\n\n"
            
            for coffee_type, data in prices['international'].items():
                if data.get('current_price'):
                    trend = "üìà" if data.get('change', 0) > 0 else "üìâ"
                    
                    message += f"**{data.get('name', coffee_type.upper())}**\n"
                    message += f"üí∞ Gi√°: {data['current_price']:,.2f} {data.get('unit', '')}\n"
                    
                    if 'change' in data:
                        message += f"{trend} Thay ƒë·ªïi: {data['change']:+.2f} "
                        if 'change_percent' in data:
                            message += f"({data['change_percent']:+.2f}%)"
                        message += "\n"
                    
                    if 'day_low' in data and 'day_high' in data:
                        message += f"üìä Bi√™n ƒë·ªô: {data['day_low']:,.2f} - {data['day_high']:,.2f}\n"
                    
                    if 'volume' in data:
                        message += f"üìà Volume: {data['volume']:,.0f}\n"
                    
                    message += "\n"
        
        # Gi√° Vi·ªát Nam
        if prices.get('vietnam'):
            message += "üáªüá≥ **TH·ªä TR∆Ø·ªúNG VI·ªÜT NAM**\n\n"
            
            for location, data in prices['vietnam'].items():
                if isinstance(data, dict) and 'price' in data:
                    trend = "üìà" if data.get('change', 0) > 0 else "üìâ"
                    
                    message += f"**{location.replace('_', ' ').title()}**\n"
                    message += f"üìç {data.get('location', '')}\n"
                    message += f"üí∞ Gi√°: {data['price']:,.0f} {data.get('unit', 'VND/kg')}\n"
                    
                    if 'change' in data:
                        message += f"{trend} Thay ƒë·ªïi: {data['change']:+,.0f} VND\n"
                    
                    message += "\n"
        
        # Ph√¢n t√≠ch th·ªã tr∆∞·ªùng
        message += "=" * 35 + "\n"
        message += "üìä **PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG**\n"
        message += self.generate_market_analysis(prices)
        
        return message
    
    def generate_market_analysis(self, prices: Dict) -> str:
        """
        T·∫°o ph√¢n t√≠ch th·ªã tr∆∞·ªùng t·ª± ƒë·ªông
        """
        analysis = []
        
        # Ph√¢n t√≠ch gi√° qu·ªëc t·∫ø
        if prices.get('international'):
            robusta = prices['international'].get('robusta', {})
            arabica = prices['international'].get('arabica', {})
            
            if robusta.get('change_percent') and arabica.get('change_percent'):
                r_change = robusta['change_percent']
                a_change = arabica['change_percent']
                
                if r_change > 0 and a_change > 0:
                    analysis.append("‚Ä¢ ‚úÖ C·∫£ hai lo·∫°i c√† ph√™ ƒë·ªÅu tƒÉng gi√°")
                elif r_change < 0 and a_change < 0:
                    analysis.append("‚Ä¢ ‚ö†Ô∏è Th·ªã tr∆∞·ªùng ƒëang ƒëi·ªÅu ch·ªânh gi·∫£m")
                else:
                    analysis.append("‚Ä¢ üîÑ Th·ªã tr∆∞·ªùng ƒëang ph√¢n h√≥a")
                
                if abs(r_change) > 2:
                    analysis.append(f"‚Ä¢ üí• Robusta bi·∫øn ƒë·ªông m·∫°nh: {r_change:+.2f}%")
                
                if abs(a_change) > 2:
                    analysis.append(f"‚Ä¢ üí• Arabica bi·∫øn ƒë·ªông m·∫°nh: {a_change:+.2f}%")
                
                # So s√°nh v·ªõi bi√™n ƒë·ªô ng√†y
                if robusta.get('day_high') and robusta.get('day_low'):
                    daily_range = ((robusta['day_high'] - robusta['day_low']) / robusta['day_low']) * 100
                    if daily_range > 3:
                        analysis.append(f"‚Ä¢ üìà Bi√™n ƒë·ªô Robusta cao: {daily_range:.1f}%")
        
        # Th√™m ghi ch√∫ v·ªÅ gi·ªù giao d·ªãch
        analysis.append("\nüí° **L∆∞u √Ω:**")
        analysis.append("‚Ä¢ Gi√° London: Giao d·ªãch 15:00-01:30 (gi·ªù VN)")
        analysis.append("‚Ä¢ Gi√° New York: Giao d·ªãch 15:30-02:20 (gi·ªù VN)")
        
        return "\n".join(analysis) if analysis else "‚Ä¢ Th·ªã tr∆∞·ªùng ·ªïn ƒë·ªãnh"
    
    def save_to_file(self, data: Dict, filename: str = "coffee_prices.json"):
        """
        L∆∞u d·ªØ li·ªáu v√†o file JSON
        """
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o {filename}")
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u file: {e}")


# S·ª≠ d·ª•ng v·ªõi Telegram integration
class CoffeePriceTelegramBot:
    """
    T√≠ch h·ª£p scraper v·ªõi Telegram
    """
    
    def __init__(self, telegram_token: str, chat_id: str):
        self.telegram_token = telegram_token
        self.chat_id = chat_id
        self.scraper = InvestingCoffeeScraper()
        self.telegram_url = f"https://api.telegram.org/bot{telegram_token}"
    
    def send_message(self, message: str) -> bool:
        """
        G·ª≠i tin nh·∫Øn qua Telegram
        """
        try:
            url = f"{self.telegram_url}/sendMessage"
            data = {
                "chat_id": self.chat_id,
                "text": message,
                "parse_mode": "Markdown",
                "disable_web_page_preview": True
            }
            
            response = requests.post(url, json=data)
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"L·ªói g·ª≠i Telegram: {e}")
            return False
    
    def run(self):
        """
        Ch·∫°y workflow ch√≠nh
        """
        logger.info("üöÄ B·∫Øt ƒë·∫ßu Coffee Price Monitor")
        
        # Scrape d·ªØ li·ªáu
        prices = self.scraper.scrape_all_prices()
        
        # L∆∞u v√†o file
        self.scraper.save_to_file(prices)
        
        # Format v√† g·ª≠i qua Telegram
        message = self.scraper.format_telegram_message(prices)
        
        if self.send_message(message):
            logger.info("‚úÖ ƒê√£ g·ª≠i b√°o c√°o qua Telegram")
        else:
            logger.error("‚ùå Kh√¥ng th·ªÉ g·ª≠i tin nh·∫Øn Telegram")
        
        return prices


if __name__ == "__main__":
    import os
    
    # Ch·∫°y scraper ƒë·ªôc l·∫≠p (kh√¥ng c·∫ßn Telegram)
    scraper = InvestingCoffeeScraper()
    prices = scraper.scrape_all_prices()
    
    # In k·∫øt qu·∫£
    print(json.dumps(prices, indent=2, ensure_ascii=False))
    
    # L∆∞u v√†o file
    scraper.save_to_file(prices)
    
    # N·∫øu c√≥ Telegram config th√¨ g·ª≠i
    TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
    CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')
    
    if TELEGRAM_TOKEN and CHAT_ID:
        bot = CoffeePriceTelegramBot(TELEGRAM_TOKEN, CHAT_ID)
        bot.run()