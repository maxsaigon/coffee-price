# test_scraper.py - Script ki·ªÉm tra scraper
import sys
import json
from datetime import datetime

def test_basic_scraping():
    """Test c∆° b·∫£n scraping t·ª´ Investing.com"""
    from investing_coffee_scraper import InvestingCoffeeScraper
    
    print("=" * 50)
    print("üß™ KI·ªÇM TRA SCRAPER")
    print("=" * 50)
    
    scraper = InvestingCoffeeScraper()
    
    # Test scraping Robusta
    print("\n1Ô∏è‚É£ Test Robusta (London)...")
    robusta_html = scraper.get_page_content(scraper.urls['robusta']['url'])
    
    if robusta_html:
        print("‚úÖ ƒê√£ l·∫•y ƒë∆∞·ª£c HTML Robusta")
        robusta_data = scraper.parse_coffee_price(robusta_html, 'robusta')
        
        if robusta_data and 'current_price' in robusta_data:
            print(f"‚úÖ Gi√° Robusta: ${robusta_data['current_price']}")
            print(f"   Change: {robusta_data.get('change', 'N/A')}")
            print(f"   Volume: {robusta_data.get('volume', 'N/A')}")
        else:
            print("‚ö†Ô∏è Kh√¥ng parse ƒë∆∞·ª£c gi√° Robusta")
    else:
        print("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p trang Robusta")
    
    # Test scraping Arabica
    print("\n2Ô∏è‚É£ Test Arabica (New York)...")
    arabica_html = scraper.get_page_content(scraper.urls['arabica']['url'])
    
    if arabica_html:
        print("‚úÖ ƒê√£ l·∫•y ƒë∆∞·ª£c HTML Arabica")
        arabica_data = scraper.parse_coffee_price(arabica_html, 'arabica')
        
        if arabica_data and 'current_price' in arabica_data:
            print(f"‚úÖ Gi√° Arabica: {arabica_data['current_price']} cents/lb")
            print(f"   Change: {arabica_data.get('change', 'N/A')}")
            print(f"   Volume: {arabica_data.get('volume', 'N/A')}")
        else:
            print("‚ö†Ô∏è Kh√¥ng parse ƒë∆∞·ª£c gi√° Arabica")
    else:
        print("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p trang Arabica")
    
    # Test full scraping
    print("\n3Ô∏è‚É£ Test full scraping...")
    all_prices = scraper.scrape_all_prices()
    
    if all_prices and all_prices.get('international'):
        print("‚úÖ Scraping ho√†n t·∫•t!")
        print(f"   S·ªë lo·∫°i c√† ph√™ qu·ªëc t·∫ø: {len(all_prices['international'])}")
        print(f"   S·ªë ngu·ªìn VN: {len(all_prices.get('vietnam', {}))}")
        
        # L∆∞u k·∫øt qu·∫£ test
        test_file = f"test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(all_prices, f, ensure_ascii=False, indent=2)
        print(f"\nüìÅ K·∫øt qu·∫£ ƒë√£ l∆∞u v√†o: {test_file}")
        
        # Test format message
        print("\n4Ô∏è‚É£ Test format Telegram message...")
        message = scraper.format_telegram_message(all_prices)
        print("üì± Preview tin nh·∫Øn Telegram:")
        print("-" * 40)
        print(message[:500] + "..." if len(message) > 500 else message)
        print("-" * 40)
        
        return True
    else:
        print("‚ùå Scraping th·∫•t b·∫°i")
        return False

def test_with_selenium():
    """
    Backup option: S·ª≠ d·ª•ng Selenium n·∫øu requests b·ªã block
    """
    print("\n" + "=" * 50)
    print("üåê TEST V·ªöI SELENIUM (Backup Option)")
    print("=" * 50)
    
    try:
        from selenium import webdriver
        from selenium.webdriver.common.by import By
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        
        # C·∫•u h√¨nh Chrome headless
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        driver = webdriver.Chrome(options=chrome_options)
        
        # Test v·ªõi Robusta
        print("\nüîÑ ƒêang test v·ªõi Selenium...")
        driver.get('https://www.investing.com/commodities/london-coffee')
        
        # ƒê·ª£i element load
        wait = WebDriverWait(driver, 10)
        price_element = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test="instrument-price-last"]'))
        )
        
        price = price_element.text
        print(f"‚úÖ Gi√° Robusta (via Selenium): {price}")
        
        driver.quit()
        return True
        
    except ImportError:
        print("‚ö†Ô∏è Selenium ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        print("   Ch·∫°y: pip install selenium")
        print("   V√† c√†i ƒë·∫∑t ChromeDriver")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói Selenium: {e}")
        return False

def test_cloudflare_bypass():
    """
    Test bypass Cloudflare protection n·∫øu c√≥
    """
    print("\n" + "=" * 50)
    print("üõ°Ô∏è TEST CLOUDFLARE BYPASS")
    print("=" * 50)
    
    try:
        import cloudscraper
        
        scraper = cloudscraper.create_scraper()
        response = scraper.get('https://www.investing.com/commodities/london-coffee')
        
        if response.status_code == 200:
            print("‚úÖ Cloudscraper ho·∫°t ƒë·ªông t·ªët")
            print(f"   Response length: {len(response.text)} chars")
            
            # Ki·ªÉm tra c√≥ data kh√¥ng
            if 'instrument-price' in response.text:
                print("‚úÖ T√¨m th·∫•y data gi√° trong response")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y data gi√°")
            
            return True
        else:
            print(f"‚ùå Status code: {response.status_code}")
            return False
            
    except ImportError:
        print("‚ö†Ô∏è Cloudscraper ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        print("   Ch·∫°y: pip install cloudscraper")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA H·ªÜ TH·ªêNG")
    print(f"‚è∞ Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Test 1: Basic scraping
    basic_test = test_basic_scraping()
    
    # Test 2: Cloudflare bypass (n·∫øu basic fail)
    if not basic_test:
        print("\n‚ö†Ô∏è Basic scraping th·∫•t b·∫°i, th·ª≠ Cloudflare bypass...")
        cf_test = test_cloudflare_bypass()
        
        # Test 3: Selenium (last resort)
        if not cf_test:
            print("\n‚ö†Ô∏è Cloudflare bypass th·∫•t b·∫°i, th·ª≠ Selenium...")
            selenium_test = test_with_selenium()
    
    print("\n" + "=" * 50)
    print("üìä K·∫æT QU·∫¢ KI·ªÇM TRA")
    print("=" * 50)
    
    if basic_test:
        print("‚úÖ H·ªá th·ªëng ho·∫°t ƒë·ªông t·ªët v·ªõi requests c∆° b·∫£n")
    else:
        print("‚ö†Ô∏è C·∫ßn s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p bypass")
        print("   ƒê·ªÅ xu·∫•t: S·ª≠ d·ª•ng Cloudscraper ho·∫∑c Selenium")
        print("\nüìå H∆Ø·ªöNG D·∫™N X·ª¨ L√ù:")
        print("1. Th·ª≠ v·ªõi Cloudscraper tr∆∞·ªõc (nhanh h∆°n)")
        print("2. N·∫øu kh√¥ng ƒë∆∞·ª£c, d√πng Selenium")
        print("3. C√¢n nh·∫Øc s·ª≠ d·ª•ng proxy rotation")
        print("4. Ho·∫∑c chuy·ªÉn sang API ch√≠nh th·ª©c (n·∫øu c√≥)")
    
    print("\n‚ú® Test ho√†n t·∫•t!")